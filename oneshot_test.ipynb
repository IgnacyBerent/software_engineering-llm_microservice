{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\n",
    "    {\n",
    "        \"Conversation\": \"\"\"\n",
    "            User1: Hi, how are you?\n",
    "            User2: I'm good, thanks! How about you?\n",
    "            User1: I'm doing well. Did you finish the project?\n",
    "            User2: Yes, I submitted it yesterday.\n",
    "            User1: Great! Let's discuss the next steps.\n",
    "        \"\"\",\n",
    "        \"Summary\": \"\"\"\n",
    "            User 2 announced that he finished the project\n",
    "        \"\"\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "Summarize shortly the most important aspects of the plot of the following conversation between multiple users like in the following example:\n",
    "\n",
    "{Conversation}\n",
    "\n",
    "Example Summary:\n",
    "{Summary}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "        input_variables=[\"Conversation\", \"Summary\"],\n",
    "        template=example_template\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize shortly the most important aspects of the plot of the following conversation between multiple users like in the following example:\n",
      "\n",
      "\n",
      "            User1: Hi, how are you?\n",
      "            User2: I'm good, thanks! How about you?\n",
      "            User1: I'm doing well. Did you finish the project?\n",
      "            User2: Yes, I submitted it yesterday.\n",
      "            User1: Great! Let's discuss the next steps.\n",
      "        \n",
      "\n",
      "Example Summary:\n",
      "\n",
      "            User 2 announced that he finished the project\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**example[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template = \"\"\"\n",
    "Conversation:\n",
    "\n",
    "{input}\n",
    "\n",
    "Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=example, \n",
    "    example_prompt=example_prompt,\n",
    "    suffix=input_template,\n",
    "    input_variables=[\"input\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = \"\"\"\n",
    "User1: Python has the worst package manager I've worked with, IMO.\n",
    "User2: Npm?\n",
    "User3: What's so bad about npm?\n",
    "User2: I used npx CRA yesterday, and three errors popped up on a stable version.\n",
    "User1: I also have no clue what problem Anaconda is supposed to solve, because from my experience, it's even more complicated than venv.\n",
    "User3: Well, you're answering your own question.\n",
    "User3: Just don't use CRA.\n",
    "User3: Vite.\n",
    "User3: npm create vite@latest\n",
    "User4: Agreed, Vite is better.\n",
    "User3: Even the official React documentation now prefers Vite over CRA.\n",
    "User2: Oh, cool.\n",
    "User2: Thanks.\n",
    "User5: C++ is watching.\n",
    "User3: Alright, you win.\n",
    "User1: I've never written in C++.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize shortly the most important aspects of the plot of the following conversation between multiple users like in the following example:\n",
      "\n",
      "\n",
      "            User1: Hi, how are you?\n",
      "            User2: I'm good, thanks! How about you?\n",
      "            User1: I'm doing well. Did you finish the project?\n",
      "            User2: Yes, I submitted it yesterday.\n",
      "            User1: Great! Let's discuss the next steps.\n",
      "        \n",
      "\n",
      "Example Summary:\n",
      "\n",
      "            User 2 announced that he finished the project\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "\n",
      "\n",
      "User1: Python has the worst package manager I've worked with, IMO.\n",
      "User2: Npm?\n",
      "User3: What's so bad about npm?\n",
      "User2: I used npx CRA yesterday, and three errors popped up on a stable version.\n",
      "User1: I also have no clue what problem Anaconda is supposed to solve, because from my experience, it's even more complicated than venv.\n",
      "User3: Well, you're answering your own question.\n",
      "User3: Just don't use CRA.\n",
      "User3: Vite.\n",
      "User3: npm create vite@latest\n",
      "User4: Agreed, Vite is better.\n",
      "User3: Even the official React documentation now prefers Vite over CRA.\n",
      "User2: Oh, cool.\n",
      "User2: Thanks.\n",
      "User5: C++ is watching.\n",
      "User3: Alright, you win.\n",
      "User1: I've never written in C++.\n",
      "\n",
      "\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input=input_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_models_list = [\n",
    "    \"llama3.2:latest\",\n",
    "    \"mistral:latest\",\n",
    "    \"mistrallite:latest\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3.2:latest\n",
      "The conversation revolves around package managers for web development, specifically:\n",
      "\n",
      "- User1 criticizes Python's package manager\n",
      "- User2 compares it to npm, citing a frustrating experience with npx CRA\n",
      "- User3 recommends Vite over CRA and provides an example command to create a new project with Vite\n",
      "- Users 4 and 5 (not present in the original conversation but part of the summary) agree that Vite is better than CRA.\n",
      "-------------------------------------------------------------------------------------\n",
      "mistral:latest\n",
      " Users discussed their experiences with different package managers and build tools, agreeing that Vite was a preferred alternative to Create React App (CRA), citing issues with errors and complexity of other solutions like Anaconda. The conversation ended with a humorous mention of C++.\n",
      "-------------------------------------------------------------------------------------\n",
      "mistrallite:latest\n",
      "User1 expressed their dissatisfaction with Python's package manager and compared it unfavorably to npm. User2 then asked what was wrong with npm, which led to a discussion about the stability of certain project versions. This sparked a broader conversation about other package managers, such as Vite, Anaconda, and venv. User3 offered suggestions for alternatives, specifically recommending Vite and advising against CRA. The official React documentation was then cited in support of this recommendation. Finally, the conversation turned to coding languages, with User1 expressing their unfamiliarity with C++.\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in ollama_models_list:\n",
    "    llm = OllamaLLM(model=model)\n",
    "    print(model)\n",
    "    print(llm.invoke(prompt.format(input=input_example)))\n",
    "    print(\"-------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
